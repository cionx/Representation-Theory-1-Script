\section{Abstract Root Systems}


\begin{convention}
  For this section let~$\kf$ be an arbitrary field of characteristic~$0$.
  All occuring vector spaces are over~$\kf$ unless otherwise stated.
  We denote for every vector space~$V$ by~$\pair{-,-} \colon V \times V^* \to \kf$ the bilinear evaluation map~$\pair{v, \varphi} = \varphi(v)$.
\end{convention}


\begin{recall}
  \leavevmode
  \begin{enumerate}
    \item
      Let~$V$ be a finite dimensional real product space with inner product~$\inner{-,-}$.
      Then for every linear subspace~$U$ of~$V$,
      \[
        V
        =
        U \oplus U^\perp \,.
      \]
      The \defemph{orthogonal reflection}\index{orthogonal reflection}\index{reflection!orthogonal} at~$U$ is the linear map~$s \colon V \to V$ given by~$s(u + u') = u - u'$ for all~$u \in U$ and~$u' \in U^\perp$, i.e.\ the unique linear map~$s \colon V \to V$ with~$\restrict{s}{U} = \id_U$ and~$\restrict{s}{U^\perp} = - \id_{U^\perp}$.
      If~$p \colon V \to V$ denotes the orthogonal projection onto~$U^\perp$, given by~$p(u + u') = u'$ for all~$u \in U$ and~$u' \in U^\perp$, then
      \[
        s(v)
        =
        v - 2 p(v)
      \]
      for every~$v \in V$.
      
      If~$H$ is a hyperplane in~$V$, i.e.\ a linear subspace of codimension~$1$\index{hyperplane}, then the orthogonal complement~$H^\perp$ is {\onedimensional} and thus of the form~$H^\perp = \gen{\alpha}_{\kf}$ for some nonzero~$\alpha \in V$.
      The orthogonal projection~$p$ onto~$H^\perp = \gen{\alpha}_{\kf}$ is given by
      \[
        p(v)
        =
        \frac{\inner{v,\alpha}}{\inner{\alpha,\alpha}} \,.
      \]
      The orthogonal reflection~$s$ at~$H$ is thus given by
      \[
        s(v)
        =
        v - 2 p(v)
        =
        v - 2 \frac{\inner{v,\alpha}}{\inner{v,v}} \,.
      \]
      The reflection at~$H$ can thus be parametrized by~$\alpha$, and can therefore be denoted by~$s_\alpha$.
    \item
      Suppose more generally that~$V$ is any vector space over an arbitrary field~$\kf$ and that~$(-,-)$ is a non-degenerate symmetric bilinear form on~$V$.
      Then for a subspace~$U$ of~$V$ the following conditions are equivalent (as seen in \cref{reviewing orthogonals}):
      \begin{equivalenceslist}
        \item
          $V = U \oplus U^\perp$.
        \item
          The restriction~$\restrict{\inner{-,-}}{U}$ is non-degenerate.
        \item
          The restriction~$\restrict{\inner{-,-}}{U^\perp}$ is non-degenerate.
      \end{equivalenceslist}
      If these conditions are satisfied then we can again consider the orthogonal reflection at the linear subspace~$U$.
      If~$H$ is a hyperplane in~$V$ then the orthogonal~$H^{\perp}$ is {\onedimensional} (since~$\dim V = \dim U + \dim U^\perp$) and thus of the form~$H^{\perp} = \gen{\alpha}_\kf$ for some nonzero~$\alpha \in V$.
      That~$\restrict{\inner{-,-}}{H^\perp}$ is non-degenerate means~$\inner{\alpha, \alpha} \neq 0$.
      The orthogonal reflection at~$H$ is then again given by
      \[
        s_\alpha(v)
        =
        v - 2 \frac{\inner{v,\alpha}}{\inner{\alpha,\alpha}} \,.
      \]
      (Since this map fixes~$H$ pointwise and maps~$\alpha$ to~$-\alpha$.)
    \item
      In the above situation a map~$t \colon V \to V$ is an \defemph{isometry}\index{isometry} with respect to~$\inner{-,-}$ if
      \[
        \inner{t(v), t(w)}
        =
        \inner{v,w}
      \]
      for all~$v, w \in V$.
      Then~$t$ is necessarily invertible because~$\inner{-,-}$ is non-degenerate.
      (If~$v \in \ker(t)$ then~$\inner{v,w} = \inner{t(v),t(w)} = 0$ for every~$w \in V$ and thus~$v = 0$.)
      
      If~$\inner{\alpha, \alpha} \neq 0$ then the above reflection~$s_\alpha$ is such an isometry:
      It sufficies to check the condition~$\inner{s_\alpha(v), s_\alpha(w)} = \inner{v,w}$ for~$v, w \in H, \gen{\alpha}_{\kf}$ because~$V = H \oplus \gen{\alpha}_{\kf}$.
      For~$v, w \in \gen{\alpha}_{\kf}$ it furthermore sufficies to consider the case~$v, w = \alpha$.
      Then
      \begin{alignat*}{2}
        \inner{s_\alpha(v), s_\alpha(w)}
        &=
        \inner{v, w}
        &
        \quad
        &\text{for~$v, w \in H$} \,,
        \\
        \inner{s_\alpha(v), s_\alpha(\alpha)}
        &=
        \inner{v, -\alpha}
        =
        -\inner{v,\alpha}
        =
        0
        =
        \inner{v, \alpha}
        &
        \quad
        &\text{for~$v \in H$} \,,
        \\
        \inner{s_\alpha(\alpha), s_\alpha(w)}
        &=
        \inner{-\alpha, w}
        =
        -\inner{\alpha, w}
        =
        0
        =
        \inner{\alpha, w}
        &
        \quad
        &\text{for~$w \in H$} \,,
        \\
        \inner{s_\alpha(\alpha), s_\alpha(\alpha)}
        &=
        \inner{-\alpha, -\alpha}
        =
        -\inner{\alpha,\alpha} \,.
        &
        {}
        &
        {}
      \end{alignat*}
      
      If~$t \colon V \to V$ is any isometry and~$\inner{\alpha, \alpha} \neq 0$ for some~$\alpha \in V$ then also~$\inner{t(\alpha), t(\alpha)} = \inner{\alpha, \alpha} \neq 0$.
      We can then consider both the reflection~$s_\alpha$ and~$s_{t(\alpha)}$.
      These are related by the formula
      \[
        s_{t(\alpha)}
        =
        t \circ s_{\alpha} \circ t^{-1} \,.
      \]
      Indeed, the transformation~$t s_{\alpha} t^{-1}$ maps the vetcor~$t(\alpha)$ to its negative, and fixes pointwise the hyperplane~$t(\alpha^\perp)$.
      Now~$t(\alpha^\perp) = t(\alpha)^\perp$ since~$t$ is an isometry.
      Hence~$t s_{\alpha} t^{-1}  = s_{t(\alpha)}$ as claimed.
  \end{enumerate}
\end{recall} 


\begin{definition}
  A \defemph{reflection}\index{reflection} in a vector space~$V$ is a map~$s \colon V \to V$ with~$s^2 = \id_V$ and such that the fixed subspace~$\{v \in V \suchthat s(v) = v\}$ has codimension~$1$.
\end{definition}


\begin{lemma}
  Let~$V$ be a vector space and let~$s \colon V \to V$ be a linear map.
  The following conditions on~$V$ are equivalent:
  \begin{enumerate}
    \item
      \label{is a reflection}
      $s$ is a reflection.
    \item
      \label{is suitable diagonalizable}
      $s$ is diagonalizable with~$V = V_+ \oplus V_-$ where~$V_+ = \{v \in V \suchthat s(v) = v\}$ has codimension~$1$ and~$V_- = \{v \in V \suchthat s(v) = -v\}$ is {\onedimensional}.
    \item
      \label{existence of dual check}
      There exist~$\alpha \in V$ and~$\check*{\alpha} \in V^*$ with~$\pair{\alpha, \check{\alpha}} = 2$ such that~$s(v) = v - \pair{v, \check{\alpha}} \alpha$ for every~$v \in V$.
  \end{enumerate}
  Then~$V_+ = \ker(\alpha)$ and~$V_- = \gen{\alpha}_{\kf}$.
\end{lemma}


\begin{proof}
  \leavevmode
  \begin{implicationlist}
    \item[\ref*{existence of dual check}~$\implies$~\ref*{is a reflection}]
      We have
      \begin{gather}
        \label{checking flip vector}
        s(\alpha)
        =
        \alpha - \pair{\alpha, \check{\alpha}} \alpha
        =
        \alpha - 2 \alpha
        =
        -\alpha
      \shortintertext{and thus}
        s^2(v)
        =
        s(v - \pair{v, \check{\alpha}} \alpha)
        =
        s(v) - \pair{v, \check{\alpha}} s(\alpha)
        =
        v - \pair{v, \check{\alpha}} \alpha + \pair{v, \check{\alpha}} \alpha
        =
        v \,.
        \notag
      \end{gather}
      for every~$v \in V$.
      This shows~$s^2 = \id_V$.
      It follows from~$\pair{\alpha, \check{\alpha}} = 2$ that~$\alpha \neq 0$ and~$\check{\alpha} \neq 0$.
      Thus
      \begin{equation}
        \label{hyperplane is kernel}
        \{
          v \in H
        \suchthat
          s(v) = v
        \}
        =
        \{
          v \in H
        \suchthat
          v - \pair{v, \check{\alpha}} \alpha = vs_{s_\alpha(\beta), \spacing s_{\check{\alpha}}(\check{\beta})}
        \}
        =
        \{
          v \in H
        \suchthat
          \pair{v, \check{\alpha}} = 0
        \}
        =
        \ker(\check{\alpha})
      \end{equation}
      has codimension~$1$.

    \item[\ref*{is a reflection}~$\implies$~\ref*{is suitable diagonalizable}]
      The endomorphism~$s$ satisfies the polynomial~$x^2 - 1 = (x-1)(x+1)$ and is therefore diagonalizable with possible eigenvalues~$1$ and~$-1$.
      Thus~$V = V_+ \oplus V_-$.
      The space~$V_+$ has codimension~$1$ because~$s$ is a reflection, so~$V_-$ is {\onedimensional}.
    \item[\ref*{is suitable diagonalizable}~$\implies$~\ref*{existence of dual check}]
      Let~$\alpha \in V_-$ be nonzero.
      Then~$V = V_+ \oplus \gen{\alpha}_{\kf}$ and thus there exists a unique linear functional~$\check*{\alpha} \in V^*$ with~$\restrict{\check{\alpha}}{V_+} = 0$ and~$\pair{\alpha, \check{\alpha}} = 2$.
      For the resulting linear map
      \begin{gather*}
        s_{\alpha, \check{\alpha}}
        \colon
        V
        \to
        V \,,
        \quad
        v
        \mapsto
        v - \pair{v, \check{\alpha}} \alpha
      \shortintertext{we have}
        \restrict{s_{\alpha, \check{\alpha}}}{V_+}
        =
        \id_{V_+}
        =
        \restrict{s}{V_+}
      \shortintertext{and}
        s_{\alpha, \check{\alpha}}(\alpha)
        =
        \alpha - \pair{\alpha, \check{\alpha}} \alpha
        =
        \alpha - 2 \alpha
        =
        -\alpha
        =
        s(\alpha) \,.
      \end{gather*}
      Thus~$s = s_{\alpha, \check{\alpha}}$ since~$V = V_+ \oplus \gen{\alpha}_{\kf}$.
  \end{implicationlist}
  That~$V_+ = \ker(\check{\alpha})$ was shown in~\eqref{hyperplane is kernel} and that~$V_- = \gen{\alpha}_{\kf}$ follows from~\eqref{checking flip vector}.
\end{proof}


\begin{definition}
  Let~$V$ be a vector space.
  For~$\alpha \in V$ and~$\check*{\alpha} \in V^*$ the \defemph{associated reflections} are the reflection
  \begin{alignat*}{2}
    s_{\alpha, \check{\alpha}}
    &\colon
    V
    \to
    V \,,
    &
    \quad
    v
    &\mapsto
    v - \pair{v, \check{\alpha}} \alpha
  \shortintertext{and}
    s_{\check{\alpha}, \alpha}
    &\colon
    V^*
    \to
    V^* \,,
    &
    \quad
    \varphi
    &\mapsto
    \varphi - \check{\alpha, \varphi} \check{\alpha} \,.
  \end{alignat*}
\end{definition}


\begin{remark}
  Let~$V$ be a vector space and let~$\alpha \in V$ and~$\check*{\alpha} \in V^*$ with~$\pair{\alpha, \check{\alpha}} = 2$.
  The element~$\alpha$ of~$V$ results in an element~$\dcheck{\alpha} \in V^{**}$ given by~$\pair{\varphi, \dcheck{\alpha}} = \pair{\alpha, \varphi}$ for every~$\varphi \in V^*$.
  In particular~$\pair{\check{\alpha}, \dcheck{\alpha}} = \pair{\alpha, \check{\alpha}} = 2$.
  It follows that~$s_{\check{\alpha}, \alpha} = s_{\check{\alpha}, \dcheck{\alpha}}$ is indeed a reflection.
\end{remark}


\begin{recall}
  If~$f \colon V \to W$ is a linear map betblnde ween finite dimensional vector spaces~$V$ and~$W$ then there exists a unique linear map~$f^* \colon W^* \to V^*$ with
  \[
    \pair{\spacing f(v), \varphi} = \pair{v, f^*(\varphi)}
  \]
  for all~$v \in V$ and~$\varphi \in W^*$.
  The map~$f^*$ is the \defemph{dual}\index{dual map}\index{map!dual} or \defemph{transpose}\index{transpose map}\index{map!transpose} of~$f$, and is given by~$f^*(\varphi) \defined \varphi \circ f$.
  We find that
  \begin{gather*}
    \ker( \spacing f^*(\varphi) )
    =
    \spacing f^{-1}(\ker(\varphi))
  \shortintertext{because}
    \begin{aligned}
    v \in \ker( \spacing f^*(\varphi) )
    &\iff
    \pair{v, \spacing f^*(\varphi)} = 0
    \\
    &\iff
    \pair{\spacing f(v), \varphi} = 0
    \\
    &\iff
    f(v) \in \ker(\varphi)
    \\
    &\iff
    v \in \spacing f^{-1}(\ker(\varphi))
    \end{aligned}
  \end{gather*}
  for every~$v \in V$.
  If~$f$ is invertible then so is~$f^*$ with~$(\spacing f^*)^{-1} = (\spacing f^{-1})^* \defines f^{-*}$.
\end{recall}


\begin{lemma}
  Let~$V$ be a finite dimensional vector space.
  Let~$\alpha \in V$ and~$\check{\alpha} \in V^*$ with~$\pair{\alpha, \check{\alpha}} = 2$, and let~$t \colon V \to V$ be an isomorphism.
  Then
  \begin{enumerate}
    \item
      $s_{\check{\alpha}, \alpha} = s_{\alpha, \check{\alpha}}^*$ and
    \item
      $t \circ s_{\alpha, \check{\alpha}} \circ t^{-1} = s_{t(\alpha), t^{-*}(\check{\alpha})}$.
  \end{enumerate}
\end{lemma}


\begin{proof}
  \leavevmode
  \begin{enumerate}
    \item
      We have for every~$\varphi \in V^*$ and~$v \in V$ that
      \begin{align*}
        \pair{v, s_{\alpha, \check{\alpha}}^*(\varphi)}
        &=
        \pair{s_{\alpha, \check{\alpha}}(v), \varphi}
        \\
        &=
        \pair[\big]{v - \pair{v, \check{\alpha}} \alpha, \varphi}
        \\
        &=
        \pair{v, \varphi} - \pair{v, \check{\alpha}} \pair{\alpha, \varphi}
        \\
        &=
        \pair[\big]{v, \varphi - \pair{\alpha, \varphi} \check{\alpha}}
        \\
        &=
        \pair{v, s_{\check{\alpha}, \alpha}(\varphi)}
      \end{align*}
      and hence~$s_{\alpha, \check{\alpha}}^* = s_{\check{\alpha}, \alpha}$ is claimed.
    \item
      It holds that
      \[
        \pair{t(\alpha), t^{-*}(\check{\alpha})}
        =
        \pair{t^{-1}(t(\alpha)), \check{\alpha}}
        =
        \pair{\alpha, \check{\alpha}}
        =
        2
      \]
      whence the reflection~$s_{t(\alpha), t^{-*}(\check{\alpha})}$ is well-defined.
      The associated hyperplane that is pointwise fixed by~$s_{t(\alpha), t^{-*}(\check{\alpha})}$ is given by
      \[
        \ker(t^{-*}(\check{\alpha}))
        =
        \ker((t^{-1})^*(\check{\alpha}))
        =
        (t^{-1})^{-1}(\check{\alpha})
        =
        t(\ker(\check{\alpha}) \,.
      \]
      This hyperplane is also pointwise fixed by~$t \circ s_{\alpha, \check{\alpha}} \circ t^{-1}$ because~$s_{\alpha, \check{\alpha}}$ fixes pointwise the hyperplane~$\ker(\check{\alpha})$.
      The vector~$t(\alpha)$ is flipped by~$s_{t(\alpha), t^{-*}(\check{\alpha})}$ and also flipped by~$t \circ s_{\alpha, \check{\alpha}} \circ t^{-1}$ because~$s_{\alpha, \check{\alpha}}$ flips the vector~$\alpha$.
      This shows that indeed~$t \circ s_{\alpha, \check{\alpha}} \circ t^{-1} = s_{t(\alpha), t^{-*}(\alpha)}$.
    \qedhere
  \end{enumerate}
\end{proof}

% 
% \begin{lemma}
%   Let~$V$ be a vector space.
%   Let~$\alpha, \beta \in V$ and~$\check{\alpha}, \check*{\beta} \in V^*$ with~$\pair{\alpha, \check{\alpha}} = \pair{\beta, \check{\beta}} = 2$.
%   We abbreviate the reflection~$s_{\alpha, \check{\alpha}}$ and~$s_{\check{\alpha}, \alpha}$ by~$s_\alpha$ and~$s_{\check{\alpha}}$, and similarly for~$s_{\beta, \check{\beta}}$ and~$s_{\check{\beta}, \beta}$.
%   Then
%   \begin{enumerate}
%     \item
%       $s_{\check{\alpha}} = s_\alpha^*$ and
%     \item
%       $s_\alpha s_\beta s_\alpha^{-1} = s_{s_\alpha(\beta), \spacing s_{\check{\alpha}}(\check{\beta})}$.
%   \end{enumerate}
% \end{lemma}

% 
% \begin{definition}
%  Let~$V$ be a vector space.
%  For~$v \in V$ and~$\lambda \in V^*$ the evaluation of~$\lambda$ at~$v$ is denoted by
%  \[
%   \pair{v, \lambda}
%   \defined
%   \pair{\lambda, v}
%   \defined
%   \lambda(v)  \,.
%  \]
% \end{definition}
% 
% 
% \begin{definition}
%   Let~$V$ be a finite dimensional vector spaces.
%   A subset~$R$ of~$V$ is an \defemph{\textup(abstract\textup) root system}\index{root system} (in~$V$) if it satisfies the following conditions:
%   \begin{enumerate}
%     \item
%       $R$ is finite,~$0 \notin R$ and~$R$ spans~$V$ as a vector space.
%     \item
%       For every~$\alpha \in R$ there exists some~$\alpha^\vee \in V^*$ such that~$\alpha^\vee(\alpha) = 2$ and~$S_{\alpha, \alpha^\vee}(R) \subseteq R$ for the linear map
%       \[
%         S_{\alpha, \alpha^\vee}
%         \colon
%         V
%         \to
%         V,
%         \quad
%         v
%         \mapsto
%         v - \pair{v, \alpha^\vee}\alpha \,.
%       \]
%     \item
%       $\pair{\alpha, \beta^\vee} \in \Integer$ for all~$\alpha, \beta \in R$.
%   \end{enumerate}
%     The root system~$R$ is \defemph{reduced}\index{reduced root system}\index{root system!reduced} if~$\kf \alpha \cap R = \{-\alpha, \alpha\}$ for every~$\alpha \in R$, i.e.\ if the only multiples of~$\alpha$ which are also roots are~$\alpha$ and~$-\alpha$.
%     The~\defemph{rank} of the root system~$R$ is the dimension of~$V$.
% \end{definition}
% % 
% % 
% % \begin{remark}\label{rem: -alpha also in the root system}
% %  Notice that if $V$ is a finite dimensional vector space and $R \subseteq V$ a root system with $\alpha \in R$ then also
% %  \[
% %   -\alpha = \alpha - 2 \alpha = \alpha - \pair{\alpha, \alpha^\vee} \alpha = S_{\alpha, \alpha^\vee}(\alpha) \in R.
% %  \]
% % \end{remark}
% % 
% % 
% % \begin{lemma}
% %  Let $V$ be a finite dimensional $k$-vector space and $R \subseteq V$ a root system. Then the element $\alpha^\vee \in V$ with $\alpha^\vee(\alpha) = 2$ is unique.
% % \end{lemma}
% % \begin{proof}
% %  Let $\alpha^\vee, \tilde{\alpha}^\vee \in V^*$ with $\alpha^\vee(\alpha) = \tilde{\alpha}^\vee(\alpha) = 2$ and $s(R) \subseteq R$ as well as $t(R) \subseteq R$ for $s \coloneqq S_{\alpha, \alpha^\vee}$ and $t \coloneqq S_{\alpha, \tilde{\alpha}^\vee}$. Notice that $s(\alpha) = t(\alpha) = -\alpha$ as already seen in Remark~\ref{rem: -alpha also in the root system}.
% %  
% %  By induction on $n$ it follows that
% %  \begin{equation}\label{eqn: iterated composition of reflections}
% %   (s \circ t)^n(x) =  x - n\pair{x,\alpha^\vee - \tilde{\alpha}^\vee} \alpha
% %   \quad \text{for every $x \in V$ and $n \geq 1$}.
% %  \end{equation}
% %  For $n = 1$ this holds because
% %  \begin{align*}
% %   s(t(x))
% %   &= s(x - \pair{x, \tilde{\alpha}^\vee}\alpha)
% %   = s(x) - \pair{x, \tilde{\alpha}^\vee} s(\alpha) \\
% %   &= x - \pair{x, \alpha^\vee}\alpha + \pair{x, \tilde{\alpha}^\vee}\alpha
% %   = x - \pair{x, \alpha^\vee - \tilde{\alpha}^\vee} \alpha.
% %  \end{align*}
% %  If the formula holds for some $n \geq 1$ then
% %  \begin{align*}
% %   (s \circ t)^{n+1}(x)
% %   &= s(t(x - n\pair{x,\alpha^\vee - \tilde{\alpha}^\vee} \alpha))
% %   = s(t(x)) - n\pair{x,\alpha^\vee - \tilde{\alpha}^\vee} s(t(\alpha)) \\
% %   &= x - \pair{x, \alpha^\vee - \tilde{\alpha}^\vee} \alpha - n\pair{x,\alpha^\vee - \tilde{\alpha}^\vee} s(t(\alpha)) \\
% %   &= x - (n+1)\pair{x, \alpha^\vee - \tilde{\alpha}^\vee} \alpha.
% %  \end{align*}
% %  
% %  Because $s$ and $t$ are automorphisms of $V$ (as a $k$-vector space) the same goes for $s \circ t$. Because $(s \circ t)(R) = s(t(R)) \subseteq s(R) \subseteq R$ and $R$ is finite it follows that the restriction $(s \circ t)|_R$ is a permutation of $R$. Since $R$ is finite $(s \circ t)|_R$ has finite order, i.e.\ there exists some $n \geq 1$ with $(s \circ t)^n|_R = \id_R$. Because $R$ spans $V$ it already follows that $(s \circ t)^n = \id_V$. Together with \eqref{eqn: iterated composition of reflections} it follows that $\pair{x, \alpha^\vee - \tilde{\alpha}^\vee} = 0$ for every $x \in V$, so $\alpha^\vee - \tilde{\alpha}^\vee = 0$ as seen in Remark~\ref{rem: natural pairing is nondegenerate}.
% % \end{proof}
% % 
% % 
% 















