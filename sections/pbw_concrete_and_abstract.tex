\section{The Poincaré--Birkhoff--Witt Theorem (Concrete and Abstract Versions)}
\label{section for concrete pbw}


\begin{convention}
  For this \lcnamecref{section for concrete pbw} we fix a Lie algebra~$\glie$ with basis~$(x_i)_{i \in I}$.
  For better readability we will denote for every element~$x$ of~$\glie$ the associated element of~$\Univ(\glie)$ by~$x$ instead of~$\class{x}$.
\end{convention}


\begin{remark}
  As a consequence of the upcoming theorem of Poincaré--Birkhoff--Witt we will see in \cref{embedding into uea} that the canonical homomorphism of Lie~algebras from~$\glie$ to~$\Univ(\glie)$ is actually injective.
  This will allow us to identify the Lie~algebra~$\glie$ with its image in~$\Univ(\glie)$.
  This will a posteriori justify our abuse of notation.
\end{remark}


\begin{fluff}
  Our results about the Weyl algebra~$A$ and its associated graded algebra~$\gr(A)$ from~\cref{results about the weyl algerba} are based on one central observation:
  the generators~$x$ and~$y$ are of degree~$1$ while their commutator~$xy - yx = -1$ is of degree~$0$.
  These generators thus \enquote{commute up to smaller degree}, whence the associated element in~$\gr(A)$ actually commute.
  
  For the universal enveloping algebra~$\Univ(\glie)$ a similar situation occurs.
  For any two elements~$x$ and~$y$ of~$\glie$ the relation~$yx = xy + [x,y]$ holds in~$\Univ(\glie)$.
  The elements~$x$ and~$y$ hence ought to commute up to smaller degree with respect to the filtration on~$\Univ(\glie)$ from~\cref{examples for filtered algebras}.

  We should therefore be able to generalize our results from \cref{results about the weyl algerba} from the Weyl algebra~$A$ to the universal enveloping algebra~$\Univ(\glie)$.
  This will lead us to the theorem of Poincaré--Birkhoff--Witt.
\end{fluff}


%\begin{fluff}
%  We already know that the universal enveloping algebra~$\Univ(\glie)$ is generated by the image of~$\glie$ in~$\Univ(\glie)$.
%  The algebra~$\Univ(\glie)$ is therefore generated by the basis elements~$x_i$ of~$\glie$.
%  This means that the momomials~$x_{i_1} \dotsm x_{i_n}$ with~$n \geq 0$,~$i_1, \dotsc, i_n \in I$ are vector space generators of~$\Univ(\glie)$.
%  By the above discussion we should hopefully be able to rearrange the terms~$x_{i_j}$ in these monomials without destroying the property of being a vector space generating set, similar to how we have done in the proof of~\cref{subspace spanned by monomials}.
%  We will see in \cref{pbw concrete generating part} that this is indeed the case.
%\end{fluff}


\begin{lemma}
  \label{rearranging lemma}
  Let~$x_1, \dotsc, x_n$ be elements of~$\glie$ and let~$\sigma$ be an element of~$\symm_n$. 
  The difference
  \[
    x_{\sigma(1)} \dotsm x_{\sigma(n)}
    -
    x_1 \dotsm x_n
  \]
  is contained in~$\Univ(\glie)_{(n-1)}$.
\end{lemma}


\begin{proof}
  We may assume that~$\sigma$ is a simple transposition, say~$\sigma = (i, i+1)$.
  It follows from the identity
  \[
    x_i x_{i+1}
    =
    x_{i+1} x_i + [x_i, x_{i+1}]
  \]
  in~$\Univ(\glie)$ that
  \begin{align*}
    x_1 \dotsm x_n
    =
    x_1 \dotsm x_i x_{i+1} \dotsm x_n
    =
    (x_1 \dotsm x_{i+1} x_i \dotsm x_n)
    +
    (x_1 \dotsm [x_i, x_{i+1}] \dotsm x_n) \,.
  \end{align*}
  The term~$x_1 \dotsm [x_i, x_{i+1}] \dotsm x_n$ is contained in~$\Univ(\glie)_{(n-1)}$.
\end{proof}


\begin{fluff}
  According to~\cref{rearranging lemma} we can rearrange for all elements~$x_1, \dotsc, x_n$ of~$\glie$ the monomial~$x_1 \dotsm x_n$ in~$\Univ(\glie)$ up to an error term of smaller degree.
  For this reording to be useful we want some canonical way in which to order the~$x_i$.
\end{fluff}


\begin{convention}
  We suppose in the following that~$(I, \leq)$ is a totally ordered set.
  \begin{enumerate}
    \item
      For every natural number~$n$ we set
      \[
        I^n
        \defined
        \{
          (i_1, \dotsc, i_n)
        \suchthat
          \text{$i_1, \dotsc, i_n \in I$ with~$i_1 \leq \dotsb \leq i_n$}
        \} \,,
      \]
      as well as~$I^{(n)} \defined \bigcup_{m=0}^n I^m$.
      We set overall~$I^* \defined \bigcup_{n \geq 0} I^n$.
    \item
      For every tupel~$\alpha$ in~$I^*$ given by~$\alpha = (i_1, \dotsc, i_n)$ we define the associated \defemph{ordered monomial}~$x_\alpha$\glsadd{ordered monomial}\index{ordered monomial} in~$\Univ(\glie)$ as
      \[
        x_\alpha
        \defined
        x_{i_1} \dotsm x_{i_n}  \,.
      \]
    \item  
      For any two elements~$\alpha$ and~$\beta$ of~$I^*$ we denote by~$\alpha \cdot \beta$ the tupel in~$I^*$ that results from the concatenation of~$\alpha$ and~$\beta$ by reordering of the entries.
      More explicitely, if~$\alpha = (i_1, \dotsc, i_n) \in I^n$ and~$\beta = (j_1, \dotsc, j_m) \in I^m$ then the concatenation of~$\alpha$ and~$\beta$ is given by~$(i_1, \dotsc, i_n, j_1, \dotsc, j_m)$.
      By reordering the entries of this tuple increasing order we arrive at the tupel~$\alpha \cdot \beta$.
    \item
      For any element~$i$ of~$I$ and every tupel~$\alpha$ in~$I^*$ we define the product~$i \cdot \alpha$ by identifying~$I$ with~$I^1$.
      More explicitely, if~$\alpha = (i_1, \dotsc, i_n)$ with~$i_1 \leq \dotsb \leq i_k \leq i \leq i_{k+1} \leq \dotsb \leq i_n$ then~$i \cdot \alpha = (i_1, \dotsc, i_k, i, i_{k+1}, \dotsc, i_n)$.
    \item
      For any element~$i$ of~$I$ and every tuple~$\alpha$ in~$I^*$ given by~$\alpha = (i_1, \dotsc, i_n)$ we write~$i \leq \alpha$ if~$i \leq i_1$.
      We have in particular for~$\alpha = ()$ that~$i \leq \alpha$ for all~$i \in I$.
  \end{enumerate}
\end{convention}


\begin{theorem}[Poincaré--Birkhoff--Witt, concrete version]
  \label{pbw concrete}
  The elements~$x_\alpha$ with~$\alpha \in I^*$ form a~{\basis{$\kf$}} of~$\Univ(\glie)$.%
  \footnote{This statement entails that these elements pairwise different, i.e. that~$x_\alpha \neq x_\beta$ whenever~$\alpha \neq \beta$.}
\end{theorem}


\begin{remark}
  The above basis of~$\Univ(\glie)$ can more explicitely be written as
  \[
    x_{i_1}^{n_1} \dotsm x_{i_r}^{n_r}
    \qquad
    \text{with~$r \geq 0$,~$i_1, \dotsc, i_r \in I$,~$i_1 < \dotsb < i_r$,~$n_1, \dotsc, n_r \geq 1$} \,.
  \]
\end{remark}


\begin{example}
  \leavevmode
  \begin{enumerate}
    \item
      If~$\glie$ is a finite-dimensional Lie algebra with basis~$x_1, \dotsc, x_r$ then the universal enveloping algebra~$\Univ(\glie)$ has the ordered monomials~$x_1^{n_1} \dotsm x_r^{n_r}$ with~$n_1, \dotsc, n_r \geq 0$ as a basis.
    \item
      A basis of~$\Univ(\sllie(2, \kf))$ is given by the ordered monomials~$e^n h^m f^k$ with~$n, m, k \geq 0$.
  \end{enumerate}
\end{example}


\begin{lemma}
  \label{pbw concrete generating part filtered part}
  The ordered monomials~$x_\alpha$ with~$\alpha$ in~$I^{(p)}$ are a vector space generating set of~$\Univ(\glie)_{(p)}$ for all~$p \geq 0$.
\end{lemma}


\begin{proof}
  We show the \lcnamecref{pbw concrete generating part filtered part} by induction over~$p$.
  It holds for~$p = 0$ because
  \[
    \Univ(\glie)_{(0)}
    =
    \gen{ 1 }_{\kf}
    =
    \gen{ x_{()} }_{\kf}
    =
    \gen{ x_\alpha \suchthat \alpha \in I^{(0)} }_{\kf}
  \]
  where~$()$ denotes the empty tupel, the only element of~$I^{(0)} = I^{0}$.
  
  Suppose now that the vector space~$\Univ(\glie)_{(p)}$ is spanned by all ordered monomils~$x_\alpha$ with~$\alpha$ in~$I^{(p)}$.
  The vector space~$\Univ(\glie)_{(p+1)}$ is spanned by all the monomials~$x_{i_1} \dotsm x_{i_{p+1}}$ with~$i_1, \dotsc, i_{p+1}$ in~$I$.
  It hence sufficies to show that every such monomials can be expressed via the proposed generators~$x_\alpha$ with~$\alpha$ in~$I^{(p+1)}$.
  We know from \cref{rearranging lemma} that
  \[
    x_{i_1} \dotsm x_{i_{n+1}}
    =
    x_\alpha + r
  \]
  for some element~$\alpha$ of~$I^{(p+1)}$ and some element~$r$ of~$\gr(\Univ(\glie))_{(p)}$ by rearranging the factors~$x_{i_j}$.
  The term~$r$ can by the induction hypothesis be expressed as a linear combination of those~$x_\beta$ with~$\beta$ in~$I^{(p)}$.
  The claim now follows because~$I^{(p)}$ is contained in~$I^{(p+1)}$.
\end{proof}


\begin{corollary}
  \label{generating for pbw}
  The ordered monomials~$x_\alpha$ with~$\alpha$ in~$I^*$ generate~$\Univ(\glie)$ as a vector space.
  \qed
\end{corollary}


\begin{lemma}
  \label{linear independence for pbw}
  The ordered monomials~$X_\alpha$ with~$\alpha$ in~$I^*$ are linearly independent.
\end{lemma}


\begin{fluff}
  To prove \cref{linear independence for pbw} we will use \cref{representation theory trick to construct a basis}.
  In the notation of \cref{representation theory trick to construct a basis} we will construct the required~\module{$\Univ(\glie)$} structure on~$M$ by considering an action of~$\glie$ on~$M$.
  We will construct this action by considering a suitable filtration~$M = \bigcup_{n=0}^\infty M_{(n)}$ and construct inductively actions
  \[
    \glie \times M_{(n)}
    \to
    M_{(n+1)} \,.
  \]
\end{fluff}


\begin{proof}[Proof of \cref{linear independence for pbw}]
  Let~$M$ be a vector space with basis~$X_\alpha$ where~$\alpha \in I^*$.
  For every natural number~$n$ we denote by~$M_{(n)}$ the linear subspace of~$M$ spanned by all those basis elements~$X_\alpha$ with~$\alpha \in I^{(n)}$.

  We show in the following that there exists a unique sequence~$(h_n)_{n \geq 0}$ of bilinear maps
  \[
    h_n
    \colon
    \glie \times M_{(n)}
    \to
    M_{(n+1)},
    \quad
    (x, m)
    \mapsto
    x \act m
  \]
  such that the following properties are satisfied.
  \begin{enumerate*}
    \item
      \label{pbw restriction coincides}
      The restriction of~$h_{n+1}$ to a map from~$\glie \times M_{(n)}$ to~$M_{(n+1)}$ coincides with the map~$h_n$, for all~$n \geq 0$.%
      \footnote{
        This condition actually follows from the other conditions by the uniqueness of the sequence~$(h_n)_{n \geq 0}$.
        See \cite[\S 17.4]{humphreys} for more details on this.
      }
    \item
      \label{pbw representation of lie algebra}
      $x_i \act x_j \act X_\alpha - x_j \act x_i \act X_\alpha = [x_i, x_j] \act X_\alpha$ for all~$i,j \in I$,~$\alpha \in I^*$.
    \item
      \label{pbw essential condition}
      $x_i \act X_\alpha = X_{i \cdot \alpha}$ for all~$i \in I$,~$\alpha \in I^*$ with $i \leq \alpha$.
    \item
      \label{pbw technical detail for construction}
      $x_i \act X_\alpha \equiv X_{i \cdot \alpha} \pmod{M_{(n)}}$ for all~$n \geq 0$,~$i \in I$,~$\alpha \in I^{(n)}$.
  \end{enumerate*}

  Let us first point out that the notation~$x \act m$ with~$x \in \glie$,~$m \in M$ is unambiguous by condition~\ref{pbw restriction coincides}.
  We will now construct the maps~$h_n$ by induction over~$n$.
  
  To define the map~$h_0$ we do not have to consider Condition~\ref*{pbw restriction coincides}.
  The linear subspace~$M_{(0)}$ is {\onedimensional} and spanned by the single element $X_{()}$.
  We see from condition~\ref*{pbw essential condition} that we need
  \[
    x_i \act X_{()}
    =
    X_{i \cdot ()}
    =
    X_i
  \]
  for all~$i \in I$.
  We take this as the definition for~$h_0$.
  Conditions~\ref{pbw essential condition} thus hold by choice of~$h_0$,~and Condition~\ref{pbw technical detail for construction} follows from this.
  Condition~\ref{pbw representation of lie algebra} does not affect the case~$n = 0$ yet.

  Let now~$n$ be a natural number and suppose that the actions maps~$h_0, \dotsc, h_n$ have already been constructed
  To construct the map~$h_{n+1}$ we need by to define the action~$x_i \act X_\alpha$ only for the elements~$\alpha$ of~$I^{n+1}$ by Condition~\ref*{pbw restriction coincides}.
  
  If~$i \leq \alpha$ then we set
  \begin{equation}
    \label{formula for smaller case}
    x_i \act X_\alpha
    \defined
    X_{i \cdot \alpha}
  \end{equation}
  to ensure that condition~\ref{pbw essential condition} holds for~$h_{p+1}$.
  Otherwise we can decompose the tupel~$\alpha$ as~$\alpha = j \cdot \beta$ where~$j$ is the first entry of~$\alpha$ and~$\beta$ is the rest of~$\alpha$.
  Then~$j \leq \beta$ and~$i > j$.
  It follows from Condition~\ref{pbw representation of lie algebra} and Condition~\ref{pbw essential condition} that we need the equalities
  \[
    x_i \act X_\alpha
    =
    x_i \act X_{j \cdot \beta}
    =
    x_i \act x_j \act X_\beta
    =
    x_j \act x_i \act X_\beta + [x_i, x_j] \act X_\beta  \,.
  \]
  The second summand~$[x_i, x_j] \act X_\beta$ is already defined by induction, and the term~$x_i \act X_\beta$ is also already defined by induction.
  For the first summand we observe that by Condition~\ref{pbw technical detail for construction} for~$h_n$ we have
  \[
    x_i \act X_\beta
    \equiv
    X_{i \cdot \beta}
    \mod
    M_{(n)}
  \]
  and hence~$x_i \act X_\beta = X_{i \cdot \beta} + R$ for some unique error term~$R$ in~$M_{(n)}$.
  It follows the inequalities~$j < i$ and~$j \leq \beta$ that~$j \leq i \cdot \beta$.
  The action~$x_j \act X_{i \cdot \beta}$ does therefore needs to be given by
  \[
    x_j \act X_{i \cdot \beta}
    =
    X_{j \cdot i \cdot \beta}
    =
    X_{i \cdot j \cdot \beta}
    =
    X_{i \cdot \alpha}  \,.
  \]
  We need altogether that
  \begin{align}
    x_i \act X_\alpha
    \notag
    &=
    x_i \act X_{j \cdot \beta}
    \notag
    \\
    &=
    x_i \act x_j \act X_\beta
    \notag
    \\
    &=
    x_j \act x_i \act X_\beta + [x_i, x_j] \act X_\beta
    \notag
    \\
    &=
    x_j \act (X_{i \cdot \beta} + R) + [x_i, x_j] \act X_\beta
    \notag
    \\
    &=
    x_j \act X_{i \cdot \beta} + x_j \act R + [x_i, x_j] \act X_\beta
    \notag
    \\
    &=
    X_{i \cdot \alpha} + x_j \act R + [x_i, x_j] \act X_\beta
    \label{formula for bigger case}
  \end{align}
  where~$j$ the first entry of~$\alpha$,~$\beta$ the rest of~$\alpha$ and the term~$R$ is given by~$R = x_i \act X_\beta - X_{i \cdot \beta}$.
  We take~\eqref{formula for bigger case} as the definition of~$x_i \act X_\alpha$ in the case~$i \nleq \alpha$.
  
  We overall defined~$h_{n+1}$ as the unique bilinear extension of~$h_n$ such that~$x_i \act X_\alpha$ is defined for the additional elements with~$\alpha$ in~$I^{n+1}$ by~\eqref{formula for smaller case} in the case~$i \leq \alpha$ and by~\eqref{formula for bigger case} in the case~$i \nleq \alpha$.
  We have also seen that the choices are forced upon us by the given conditions.
  We have therefore shown the uniqueness of the map~$h_{n+1}$.
  
  Condition~\ref{pbw restriction coincides} holds for~$h_{n+1}$ by construction of~$h_{n+1}$ as an extension of~$h_n$.

  Condition~\ref{pbw essential condition} holds for~$h_{n+1}$ by the following case distinction.
  It holds for~$\alpha$ in~$I^{(n)}$ by the corresponding property of~$h_n$.
  It holds for~$\alpha$ in~$I^{(n+1)}$ because for~$i \leq \alpha$ the element~$x_i \act X_\alpha$ is defined via the formula~\eqref{formula for smaller case}. 

  Condition~\ref{pbw technical detail for construction} holds for~$h_{n+1}$ by the following case distinction.
  For~$\alpha$ in~$I^{(n)}$ it holds by induction hypothesis.
  For~$\alpha$ in~$I^{n+1}$ and~$i \leq \alpha$ it holds by Condition~\ref{pbw essential condition}.
  For~$\alpha$ in~$I^{n+1}$ and~$i \nleq \alpha$ we have
  \[
    x_i \act X_\alpha - X_{i.\alpha}
    =
    x_j \act R + [x_i, x_j] \act X_\beta
  \]
  where~$j$ is the first entry of~$\alpha$, the tuple~$\beta$ in~$I^n$ is the rest of~$\alpha$, and~$R$ is the element of~$M_{(n+1)}$ given by~$R = x_i \act X_\beta - X_{i \cdot \beta}$.
  We need to show that the right hand side of this equality is contained in~$M_{(n+1)}$.
  The term~$[x_i, x_j] \act X_\beta$ is contained in~$M_{(n+1)}$ because~$X_\beta$ is contained in~$M_{(n)}$.
  The term~$R = x_i \act X_\beta - X_{i \cdot \beta}$ is by induction hypotheses contained in~$M_{(n)}$ because $X_\beta \equiv X_{i \cdot \beta} \pmod{M_{(n)}}$.
  The term~$x_j \act R$ is therefore also contained in~$M_{(n+1)}$.

  It remains to check Condition~\ref{pbw representation of lie algebra} for~$h_{n+1}$.
  In other words, we need to check that
  \[
    x_i \act x_j \act X_\alpha - x_j \act x_i \act X_\alpha
    =
    [x_i, x_j] \act X_\alpha
  \]
  for all~$i, j \in I$,~$\alpha \in I^{(n)}$.
  We may assume that~$\alpha$ is contained in~$I^n$ since all other cases are covered by the induction hypothesis.
  For~$i = j$ this equality holds because~$[x_i, x_i] = 0$.
  We may therefore assume in the following that~$i \neq j$.
  We show the above identity by case distinction.
  
  \begin{description}
    \item[Case~1: $i \leq \alpha$]
      We consider two subcases:
      \begin{description}
        \item[Case~1.1: $i \leq \alpha$,~$i < j$]
          It follows from the assumption~$i \leq \alpha$ that~$x_i \cdot X_\alpha = X_{i \cdot \alpha}$.
          The first entry of~$i \cdot \alpha$ is~$i$, whence it follows from the assumption~$i < j$ that~$j \nleq i \cdot \alpha$.
          It follows that the element
          \[
            x_j \act x_i \act X_\alpha
            =
            x_j \act X_{i \cdot \alpha}
          \]
          is given by
          \begin{align*}
            x_j \act X_{i \cdot \alpha}
            &=
            X_{j \cdot i \cdot \alpha}
            + x_i \act R
            + [x_j, x_i] \act X_\alpha
            \\
            &=
            X_{j \cdot i \cdot \alpha}
            + x_i \act ( x_j \act X_\alpha - X_{j \act \alpha} )
            + [x_j, x_i] \act X_\alpha
            \\
            &=
            X_{j \cdot i \cdot \alpha}
            + x_i \act x_j \act X_\alpha
            - x_i \act X_{j \act \alpha}
            + [x_j, x_i] \act X_\alpha
            \\
            &=
            X_{j \cdot i \cdot \alpha}
            + x_i \act x_j \act X_\alpha
            - x_i \act X_{j \act \alpha}
            - [x_i, x_j] \act X_\alpha
          \end{align*}
          where~$R = x_j \act X_\alpha - X_{j \act \alpha}$.
          By rearranging this equation we find that
          \begin{align*}
            x_i \act x_j \act X_\alpha - x_j \act x_i \act X_\alpha
            &=
            x_i \act x_j \act X_\alpha - x_j \act X_{i \cdot \alpha}
            \\
            &=
            x_i \act x_j \act X_\alpha
            - X_{j \cdot i \cdot \alpha}
            - x_i \act x_j \act X_\alpha
            + x_i \act X_{j \act \alpha}
            + [x_i, x_j] \act X_\alpha
            \\
            &=
            - X_{j \cdot i \cdot \alpha}
            + x_i \act X_{j \act \alpha}
            + [x_i, x_j] \act X_\alpha \,.
          \end{align*}
          It follows from the assumptions~$i < j$ and~$i \leq \alpha$ that~$i \leq j \cdot \alpha$.
          Thus~$x_i \cdot X_{j \cdot \alpha} = X_{i \cdot j \cdot \alpha} = X_{j \cdot i \cdot \alpha}$.
          It therefore further follows that
          \[
            x_i \act x_j \act X_\alpha - x_j \act x_i \act X_\alpha
            =
            - X_{j \cdot i \cdot \alpha}
            + x_i \act X_{j \act \alpha}
            + [x_i, x_j] \act X_\alpha
            =
            [x_i, x_j] \act X_\alpha \,.
          \]
        \item[Case~1.2: $i \leq \alpha$,~$i > j$]
          It follows that~$j \leq \alpha$.
          We also have~$j < i$ by assumption.
          It follows from the previous case that
          \[
            x_j \act x_i \act X_\alpha - x_i \act x_j \act X_\alpha
            =
            [x_j, x_i] \act X_\alpha \,.
          \]
          It follows that
          \begin{align*}
            \SwapAboveDisplaySkip
            [x_i, x_j].X \act \alpha
            &=
            -[x_j, x_i] \act X_\alpha
            \\
            &=
            - (x_j \act x_i \act X_\alpha - x_i \act x_j \act X_\alpha)
            \\
            &=
            x_i \act x_j \act X_\alpha - x_j \act x_i \act X_\alpha \,.
          \end{align*}
      \end{description}
    \item[Case~2: $j \leq \alpha$]
      \label{second element is smaller than monomial}
      It follows from Case~1 that
      \[
        x_j \act x_i \act X_\alpha - x_i \act x_j \act X_\alpha
        =
        [x_j, x_i] \act X_\alpha \,,
      \]
      and thus
      \begin{align*}
        \SwapAboveDisplaySkip
        [x_i, x_j] \act X_\alpha
        &=
        -[x_j, x_i] \act X_\alpha
        \\
        &=
        - (x_j \act x_i \act X_\alpha - x_i \act x_j \act X_\alpha)
        \\
        &=
        x_i \act x_j \act X_\alpha - x_j \act x_i \act X_\alpha \,.
      \end{align*}
    \item[Case~3: $i \nleq \alpha$,~$j \nleq \alpha$]
      This case cannot happen for$\alpha$ in~$n = 0$ because then~$\alpha = ()$ (since~$\alpha$ is an element of~$I^n = I^0$) and thus~$i \leq () = \alpha$.
      We may therefore assume in the following that~$n \geq 1$.

      We can thus split up the tuple~$\alpha$ as~$\alpha = k \cdot \beta$ where~$k$ is the first entry of~$\alpha$ and~$\beta$ is the rest of~$\alpha$.
      We then have
      \[
        X_\alpha
        =
        X_{k \cdot \beta}
        =
        x_k \act X_\beta \,.
      \]
      The tupel~$\beta$ is contained in~$I^{n-1}$.
      We therefore know from the induction hypothesis that
      \[
        x_j \act X_\alpha
        =
        x_j \act x_k \act X_\beta
        =
        x_k \act x_j \act X_\beta 
        + [x_j, x_k] \act X_\beta  \,.
      \]
      By acting with~$x_i$ on this equation we find the equality
      \begin{equation}
        \label{long equation}
        x_i \act x_j \act X_\alpha
        =
        x_i \act x_k \act x_j \act X_\beta
        + x_i \act [x_j,x_k] \act X_\beta \,.
      \end{equation}
      Let~$Y \defined x_j \act X_\beta$.

      \begin{claim}
        We have
        \begin{equation}
          \label{wanted equation for pbw}
          x_i \act x_k \act Y
          =
          x_k \act x_i \act Y
          + [x_i, x_k] \act Y \,.
        \end{equation}
      \end{claim}

      \begin{proof}
        The tupel~$\beta$ is contained in~$M_{(n-1)}$, so it follows from Condition~\ref{pbw technical detail for construction} that
        \[
          Y
          =
          x_j \act X_\beta
          \equiv
          X_{j \cdot \beta}
          \mod
          M_{(n-1)} \,.
        \]
        The difference~$R \coloneqq Y - X_{j \cdot \beta}$ is therefore contained in~$M_{(n-1)}$.
        We can now decompose the element~$Y$ as
        \[
          Y
          =
          X_{j \cdot \beta} + R  \,.
        \]
        The desired identity~\eqref{wanted equation for pbw} is linear in~$Y$.
        To show~\eqref{wanted equation for pbw} we will therefore show the two identities
        \begin{equation}
          \label{wanted equation for pbw small for monomial}
          x_i \act x_k \act X_{j \cdot \beta}
          =
          x_k \act x_i \act X_{j \cdot \beta}
          + [x_i, x_k] \act X_{j \cdot \beta} \,.
        \end{equation}
        and
        \begin{equation}
          \label{wanted equation for pbw small for rest}
          x_i \act x_k \act R
          =
          x_k \act x_i \act R
          + [x_i, x_k] \act R \,.
        \end{equation}
        Identity~\eqref{wanted equation for pbw small for rest} holds by induction hypothesis because~$R$ is contained in~$M_{(n-1)}$.
        For identity~\eqref{wanted equation for pbw small for monomial} we recall that~$k$ is the first term of~$\alpha$.
        Thus~$k \leq \beta$.
        It alsofollows from the condition~$j \nleq \alpha$ is equivalent to~$j > k$.
        It follows from~$k < j$ and~$k \leq \alpha$ that~$k \leq j \cdot \beta$.
        Identity~\ref{wanted equation for pbw small for monomial} does therefore follows from Case~2.
        We have altogether proven identity~\eqref{wanted equation for pbw}.
      \end{proof}

      By inserting~\eqref{wanted equation for pbw} into~\eqref{long equation} we find that
      \begin{align*}
        x_i \act x_j \act X_\alpha
        &=
        x_i \act x_k \act x_j \act X_\beta
        + x_i \act [x_j, x_k] \act X_\beta
        \\
        &=
        x_i \act x_k \act Y
        + x_i \act [x_j, x_k] \act X_\beta
        \\
        &=
        x_k \act x_i \act Y
        + [x_i, x_k] \act Y
        + x_i \act [x_j, x_k] \act X_\beta
        \\
        &=
        x_k \act x_i \act x_j \act X_\beta
        + [x_i, x_k] \act x_j \act X_\beta
        + x_i \act [x_j, x_k] \act X_\beta
      \end{align*}
      By swapping the roles of~$i$ and~$j$ we also find that
      \[
        x_j \act x_i \act X_\alpha
        =
        x_k \act x_j \act x_i \act X_\beta
        + [x_j, x_k] \act x_i \act X_\beta
        + x_j \act [x_i, x_k] \act X_\beta \,.
      \]
      It follows that
      \begin{align*}
        \SwapAboveDisplaySkip
        {}&
        x_i \act x_j \act X_\alpha
        - x_j \act x_i \act X_\alpha
        \\
        ={}&
        x_k \act x_i \act x_j \act X_\beta
        + [x_i, x_k] \act x_j \act X_\beta
        + x_i \act [x_j, x_k] \act X_\beta
        \\
        {}&
        - x_k \act x_j \act x_i \act X_\beta
        - [x_j, x_k] \act x_i \act X_\beta
        - x_j \act [x_i, x_k] \act X_\beta \,.
      \end{align*}
      We know from the induction hypothesis that
      \begin{align*}
        x_i \act x_j \act X_\beta
        - x_j \act x_i \act X_\beta
        &=
        [x_i, x_j] \act X_\beta \,,
        \\
        [x_i, x_k] \act x_j \act X_\beta
        - x_j \act [x_i, x_k] \act X_\beta
        &=
        [ [x_i, x_k], x_j ] \act X_\beta \,,
        \\
        x_i \act [x_j, x_k] \act X_\beta
        - [x_j, x_k] \act x_i \act X_\beta
        &=
        [ x_i, [x_j, x_k] ] \act X_\beta \,,
      \end{align*}
      and thus
      \begin{align*}
        \SwapAboveDisplaySkip
        {}&
        x_k \act x_i \act x_j \act X_\beta
        + [x_i, x_k] \act x_j \act X_\beta
        + x_i \act [x_j, x_k] \act X_\beta
        \\
        {}&
        - x_k \act x_j \act x_i \act X_\beta
        - [x_j, x_k] \act x_i \act X_\beta
        - x_j \act [x_i, x_k] \act X_\beta \,.
        \\
        ={}&
        x_k \act [x_i, x_j] \act X_\beta
        + [[x_i, x_k], x_j] \act X_\beta
        + [x_i, [x_j, x_k]] \act X_\beta \,.
        \\
        ={}&
        x_k \act [x_i, x_j] \act X_\beta
        + \bigl( [[x_i, x_k], x_j] + [x_i, [x_j, x_k]] \bigr) \act X_\beta
      \end{align*}
      It follows from the Jacobi~identity that
      \begin{align*}
        [[x_i, x_k], x_j] + [x_i, [x_j, x_k]]
        &=
        - [[x_k, x_i], x_j] - [x_i, [x_k, x_j]]
        \\
        &=
        - [[x_k, x_i], x_j] - [x_i, [x_k, x_j]]
        \\
        &=
        - [x_k, [x_i, x_j]] \,,
      \end{align*}
      and thus
      \begin{align*}
        \SwapAboveDisplaySkip
        {}&
        x_k \act [x_i, x_j] \act X_\beta
        + \bigl( [[x_i, x_k], x_j] + [x_i, [x_j, x_k]] \bigr) \act X_\beta
        \\
        ={}&
        x_k \act [x_i, x_j] \act X_\beta
        - [x_k, [x_i, x_j] ] \act X_\beta \,.
      \end{align*}
      By using the induction hypothesis and that~$\alpha = k \cdot \beta$ with~$k \leq \beta$ we find that
      \begin{align*}
        [x_k, [x_i, x_j]] \act X_\beta
        &=
        x_k \act [x_i, x_j] \act X_\beta
        - [x_i, x_j] \act x_k \act X_\beta
        \\
        &=
        x_k \act [x_i, x_j] \act X_\beta
        - [x_i, x_j] \act X_{k \cdot \beta}
        \\
        &=
        x_k \act [x_i, x_j] \act X_\beta
        - [x_i, x_j] \act X_{\alpha} \,.
      \end{align*}
      It thus follows that
      \begin{align*}
        {}&
        x_k \act [x_i, x_j] \act X_\beta
        - [x_k, [x_i, x_j] ] \act X_\beta
        \\
        ={}&
        x_k \act [x_i, x_j] \act X_\beta
        - x_k \act [x_i, x_j] \act X_\beta
        + [x_i, x_j] \act X_{\alpha}
        \\
        ={}&
        [x_i, x_j] \act X_{\alpha} \,.
      \end{align*}
      By putting all of these steps together we find that
      \begin{align*}
        x_i \act x_j \act X_\beta
        - x_j \act x_i \act X_\beta
        &=
        [x_i, x_j] \act X_{\alpha} \,.
      \end{align*}
  \end{description}
  We have thus shown Condition~\ref{pbw technical detail for construction} for the induction step.

  We have now constructed the maps~$h_n$ and shown their uniqueness. 
  Condition~\ref{pbw restriction coincides} ensures that thes maps combine into a single bilinear map
  \[
    h
    \colon
    \glie \times M
    \to
    M \,.
  \]
  Condition~\ref{pbw representation of lie algebra} means that~$h$ is an action of~$\glie$ on~$M$, making~$M$ into a representation of~$\glie$.
  This action corresponds to an~\module{$\Univ(\glie)$} structure on~$M$.
  For every tuple~$\alpha$ in~$I^*$ with~$\alpha = (i_1, \dotsc, i_n)$ we have~$i_1 \leq \dotsb \leq i_n$ and thus
  \begin{align*}
    \SwapAboveDisplaySkip
    x_\alpha . X_{()}
    &=
    x_{i_1} \dotsm x_{i_n} \cdot X_{()}
    \\
    &=
    x_{i_1} \dotsm x_{i_{n-1}} \cdot X_{(i_n)}
    \\
    &=
    x_{i_1} \dotsm x_{i_{n-2}} \cdot X_{(i_{n-1}, i_n)}
    \\
    &=
    \dotsb
    \\
    &=
    X_{(i_1, \dotsc, i_n)}
    \\
    &=
    X_\alpha \,.
  \end{align*}
  It now follows from the linear independence of the elements~$X_\alpha$ with~$\alpha$ in~$I^*$ that the elements~$x_\alpha$ with~$\alpha$ in~$I^*$ are linearly independent.
\end{proof}


\begin{proof}[Proof of \cref{pbw concrete}]
  It follows from \cref{generating for pbw} that the given monomials are a vector space generating set, and they are linearly indpendent by \cref{linear independence for pbw}.
\end{proof}


\begin{corollary}
  \label{pbw concrete basis part filtered part}
  The filtered part~$\Univ(\glie)_{(n)}$ has the monomials~$x_\alpha$ with~$\alpha$ in~$I^{(n)}$ as a basis, for all~$n \geq 0$.
\end{corollary}


\begin{proof}
  This follows from \cref{pbw concrete generating part filtered part} and \cref{linear independence for pbw}.
\end{proof}


\begin{theorem}[Poincaré--Birkhoff--Witt, abstract version]
  \label{pbw abstract}
  Let~$\Pi$ be the canonical quotient homomorphism from~$\Tensor(\glie)$ to~$\Univ(\glie)$, given by
  \begin{alignat*}{2}
    \Pi
    &\colon
    \Tensor(\glie)
    \to
    \Univ(\glie) \,,
    &
    \quad
    x_1 \tensor \dotsb \tensor x_n
    &\mapsto
    x_1 \dotsm x_n
  \intertext{
  for all $x_1, \dotsc, x_n \in \glie$.
  Let~$\Pi'$ be the canonical quotient homomorphism from~$\Tensor(\glie)$ to~$\Symm(\glie)$, given by
  }
    \SwapAboveDisplaySkip
    \Pi'
    &\colon
    \Tensor(\glie)
    \to
    \Symm(\glie) \,,
    &
    \quad
    x_1 \tensor \dotsb \tensor x_n
    &\mapsto
    x_1 \dotsm x_n \,.
  \end{alignat*}
  for all~$x_1, \dotsc, x_n \in \glie'$.
  The homomorphism~$\Pi$ is a homomorphism of filtered algebras and thus induces a homomorphism of graded algebras from~$\gr(\Tensor(\glie))$ to~$\gr(\Univ(\glie))$.
  We identify~$\gr(\Tensor(\glie))$ with~$\Tensor(\glie)$ and thus regard~$\gr(\Pi)$ as a homomorphism from~$\Tensor(\glie)$ to~$\gr(\Univ(\glie))$.

  The two homomorphisms~$\gr(\Pi)$ and~$\Pi'$ have the same kernel and thus induce an isomorphism of graded algebras~$\Phi$ from~$\Symm(\glie)$ to~$\Univ(\glie)$, given by
  \begin{equation}
    \label{definition of abstract pbw isomorphism}
    \Phi
    \colon
    \Symm(\glie)
    \to
    \gr(\Univ(\glie)) \,,
    \quad
    x_1 \dotsm x_n
    \mapsto
    \fclass{ x_1 \dotsm x_n }_n
  \end{equation}
  for all~$x_1, \dotsc, x_n \in \glie$.
\end{theorem}


\begin{proposition}
  The abstract versions of the PBW~theorem is equivalent to the concrete version.
\end{proposition}


\begin{proof}
  Let~$x$ and~$y$ be two elements of~$\glie$.
  The element~$x \otimes y - y \otimes x$ of~$\Tensor(\glie)$ is homogeneous of degree~$2$.
  It is mapped by the homomorphism~$\gr(\Pi)$ to the element~$\fclass{ x y - y x }_2$ of~$\gr(\Univ(\glie))$.
  But we have in~$\Univ(\glie)$ the identity~$xy - yx = [x,y]_{\glie}$, so
  \[
    \fclass{ xy - yx }_2
    =
    \fclass{ [x,y]_{\glie} }_2 \,.
  \]
  The commutator~$[x,y]_{\glie}$ is an element of~$\glie$ and thus in~$\Univ(\glie)$ of degree~$1$, i.e. this element is contained in~$\Univ(\glie)_{(1)}$.
  It follows that~$\fclass{ [x,y]_{\glie} }_2 = 0$.
  We have thus shown that the element~$x \otimes y - y \otimes x$ is contained in the kernel of~$\gr(\Pi)$, for all~$x, y \in \glie$.

  The kernel of~$\Pi'$ is generated by those differences as a two-sided ideal.
  We thus find that there exists a unique homomorphism of algebras~$\Phi$ from~$\Symm(\glie)$ to~$\gr(\Univ(\glie))$ which maps for every element~$t$ of~$\Tensor(\glie)$ the residue class of~$t$ in~$\Symm(\glie)$ to the residue class of~$t$ in~$\gr( \Univ(\glie) )$.
  This is precisely the proposed homomorphism~\eqref{definition of abstract pbw isomorphism}.
  This is a homomorphism of graded algebras because the grading on~$\Symm(\glie)$ is inherited from~$\Tensor(\glie)$ and~$\gr(\Pi)$ is a homomorphism of graded algebras.
  
  \begin{implicationlist}
    \item[concrete~$\implies$~abstract]
      It sufficies to show that for every natural number~$n$ the restriction~$\Phi_n$ of~$\Phi$ to a linear map from~$\Symm^n(\glie)$ to~$\gr[n]{\Univ(\glie)}$ is an isomorphism of vector spaces.
      The symmetric power~$\Symm^n(\glie)$ has the simple symmetric tensors~$x_{i_1} \dotsm x_{i_n}$ with~$i_1, \dotsc, i_n \in I$,~$i_1 \leq \dotsb \leq i_n$ as a basis.
      It follows from \cref{pbw concrete basis part filtered part} that~$\gr[n]{ \Univ(\glie) }$ has the elements~$\fclass{ x_{i_1} \dotsm x_{i_n} }_n$ with~$i_1, \dotsc, i_n \in $,~$i_1 \leq \dotsb \leq i_n$ as a basis.
      The linear map~$\Phi_n$ restricts to a bijection between these bases and is therefore indeed an isomorphism of vector spaces.
    \item[abstract~$\implies$~concrete]
      The symmetric algebra~$\Symm(V)$ has the elements
      \begin{align*}
        x_{i_1} \dotsm x_{i_n}
        &\qquad
        \text{with~$n \geq 0$,~$i_1, \dotsc, i_n \in I$,~$i_1 \leq \dotsb \leq i_n$}
      \intertext{
      as a basis.
      It follows that the elements
      }
        \fclass{ x_{i_1} \dotsm x_{i_n} }_n
        &\qquad
        \text{with~$n \geq 0$,~$i_1, \dotsc, i_n \in I$,~$i_1 \leq \dotsb \leq i_n$}
      \intertext{
      are a basis of~$\gr(\Univ(\glie))$ because~$\Phi$ is an isomorphism.
      It follows from \cref{checking basis via associated graded} that the elements
      }
        \SwapAboveDisplaySkip
        \fclass{ x_{i_1} \dotsm x_{i_n} }_n
        &\qquad
        \text{with~$n \geq 0$,~$i_1, \dotsc, i_n \in I$,~$i_1 \leq \dotsb \leq i_n$}
      \end{align*}
      are a basis of~$\Univ(\glie)$.
    \qedhere
  \end{implicationlist}
\end{proof}



\begin{remark}[The diamond lemma]
  The above proof of the PBW~theorem relies on a tactic from representation theory:
  constructing an action on a suitable vector space for which the given generators act linearly independent (on some fixed element).

  We may ask if there is instead a proof of the PBW~theorem which continues to study the commutator relation~$x_j x_i = x_i x_j + [x_i, x_j]$ with~$i, j \in I$ by exploiting that the commutator~$[x_i, x_j]$ ought to be of smaller degree than~$x_j x_i$ and~$x_i x_j$.
  A similar question may also be asked for the Weyl~algebra.
  
  One way to do this is via the \defemph{diamond lemma}\index{diamond lemma}\index{lemma!diamond} as introduced by Bergman in~\cite{diamond_lemma}.
  Suppose that we are given a~\algebra{$\kf$}~$A$ by generators~$x_i$ with~$i$ in~$I$ and set of relations~$S$, where~$S$ a subset of the free algebra ~$\kf\gen{x_i \suchthat i \in I}$.
  In other words, we have
  \[
    A
    =
    \kf\gen{x_i \suchthat i \in I}
    /
    \ideal{ S } \,.
  \]
  Then the diamond lemma gives a criterion for showing that~$A$ admits a basis consisting of monomials in the~$x_i$, and also tells us how these monomials can be choosen.
  
  The main idea behind the diamond lemma is that one needs to be able to resolve ambiguities.
  We can represent every element of~$A$ as a linear combination of monomials in the~$x_i$, and hence as an element~$z$ of~$\kf\gen{x_i \suchthat i \in I}$.
  Every relation~$\sigma$ between the generators, i.e. element of~$S$, can be seen as a rewriting rule.
  This gives us linear \enquote{rewriting maps}
  \[
    r_\sigma
    \colon
    \kf\gen{x_i \suchthat i \in I}
    \to
    \kf\gen{x_i \suchthat i \in I}
  \]
  for all~$\sigma \in S$.
  To apply the diamond lemma one need two conditions.
  \begin{itemize}
    \item
      Whenever we apply rewritings~$r_{\sigma_1}, r_{\sigma_2}, \dotsc$ to an element of~$\kf\gen{x_i \suchthat i \in I}$ we want this process to stabilize after finitely many step.
    \item
      We need to be resolve ambiguities.
      Given an element~$z$ of~$\kf\gen{x_i \suchthat i \in I}$ we can often apply different rewriting rules~$r_\sigma$ and~$r_\tau$ to it, resulting in different results~$r_\sigma(z)$ and~$r_\tau(z)$.
      We want to reconcile these different results by reducing both~$r_\sigma(z)$ and~$r_\tau(z)$ under finitely many rewritings to the same result~$z'$.
      We may visualize this process by the following diagram:
      \[
        \begin{tikzcd}[column sep = small]
          {}
          &
          z
          \arrow{dl}
          \arrow{dr}
          &
          {}
          \\
          r_\sigma(z)
          \arrow{dr}
          &
          {}
          &
          r_\tau(z)
          \arrow{dl}
          \\
          {}
          &
          z'
          &
          {}
        \end{tikzcd}
      \]
      The shape of this diagram motivates the name \enquote{diamond lemma}.
  \end{itemize}
  
  The diamond is neither hard to state nor to prove, despite its usefulness.
  We strongly encourage the reader to check out the original paper \cite{diamond_lemma}.
  The main theorem and its proof in \cite[\S 1]{diamond_lemma} takes only three pages and is self-contained.
  In \cite[\S 3]{diamond_lemma} the PBW~theorem is then proven as an example.
\end{remark}


\begin{remark}
  One can think about the universal enveloping algebra~$\Univ(\glie)$ as a deformation of the symmetric algebra~$\Symm(\glie)$, in the sense that we have a family of~\algebras{$\kf$}
  \[
    A_t
    \defined
    \Tensor(\glie)
    /
    \ideal{ x \tensor y - y \tensor x - t[x,y] \suchthat x, y \in \glie }
  \]
  that is parametrized by a scalar~$t$ in~$\kf$ with~$A_0 \cong \Symm(\glie)$ and~$A_1 \cong \Univ(\glie)$.
  One can actually prove the abstract version of the PBW~theorem by examining this deformation, as explained in~\cite{pbw_deformation}.
\end{remark}





